{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:01.123055Z","iopub.status.busy":"2023-12-15T17:36:01.122784Z","iopub.status.idle":"2023-12-15T17:36:31.454465Z","shell.execute_reply":"2023-12-15T17:36:31.453410Z","shell.execute_reply.started":"2023-12-15T17:36:01.123030Z"},"id":"y8_zCYtOhLvO","outputId":"01955faf-ff72-4959-a362-53579ce02c4e","trusted":true},"outputs":[],"source":["#!pip install ml_collections \"textdistance[extras]\""]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:31.456632Z","iopub.status.busy":"2023-12-15T17:36:31.456320Z","iopub.status.idle":"2023-12-15T17:36:31.477898Z","shell.execute_reply":"2023-12-15T17:36:31.476971Z","shell.execute_reply.started":"2023-12-15T17:36:31.456604Z"},"id":"vSDn-u-xYZma","trusted":true},"outputs":[],"source":["# hw2/utils.py\n","\n","import enum\n","import pickle\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","def save_obj(obj, path):\n","    with open(path, \"wb\") as f:\n","        pickle.dump(obj, f)\n","\n","\n","def save_txt(str, path):\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(str)\n","\n","\n","def load_metrics(file_path):\n","    with open(file_path, \"rb\") as f:\n","        metrics = pickle.load(f)\n","\n","    return metrics\n","\n","\n","def plot_metrics(metrics, plot_path, phase=\"train\"):\n","    metric_keys = list(metrics[0][phase].keys())\n","    len_x = len(metrics)\n","    x_label = \"epoch\".title()\n","    x = np.arange(len_x)\n","\n","    for k in metric_keys:\n","        if k == \"n\":\n","            continue\n","\n","        metric_path = plot_path / f\"{k}__{phase}.pdf\"\n","        y = np.array([metrics[i][phase][k] for i in range(len_x)])\n","\n","        if k != \"loss\":\n","            batch = np.array([metrics[i][phase][\"n\"] for i in range(len_x)])\n","            y /= batch\n","\n","        y = y.mean(axis=-1)\n","        _create_plot([y], [x], x_label, k.title(), metric_path, show=True)\n","\n","\n","def cmp_phase_metrics(metrics, key, phases, plot_path, labels):\n","    len_x = len(metrics)\n","    x_label = \"epoch\".title()\n","    x = np.arange(len_x)\n","    y = []\n","\n","    for phase in phases:\n","        y_phase = np.array([metrics[i][phase][key] for i in range(len_x)])\n","\n","        if key != \"loss\":\n","            batch = np.array([metrics[i][phase][\"n\"] for i in range(len_x)])\n","            y_phase /= batch\n","\n","        y_phase = y_phase.mean(axis=-1)\n","        y.append(y_phase)\n","\n","    x = [x] * len(y)\n","    fig_path = plot_path / f\"{key}__{'_'.join(phases)}.pdf\"\n","    labels = [labels[p] for p in phases]\n","    _create_plot(y, x, x_label, key.title(), fig_path, line_labels=labels, show=True)\n","\n","\n","def _create_plot(ys, xs, x_label, y_label, save_path, line_labels=None, show=False):\n","    fig, ax = plt.subplots()\n","    for y, x in zip(ys, xs):\n","        ax.plot(x, y)\n","\n","    ax.set_xlabel(x_label)\n","    ax.set_ylabel(y_label)\n","    ax.grid()\n","    fig.savefig(save_path, format=\"pdf\", bbox_inches=\"tight\")\n","\n","    if line_labels is not None:\n","        ax.legend(line_labels)\n","\n","    if show:\n","        plt.show(fig)\n","\n","    plt.close(fig)\n","\n","\n","class Dataset(str, enum.Enum):\n","    LJSPEECH_STFT = \"ljspeech_stft\"\n","    LJSPEECH_MEL = \"ljspeech_mel\"\n","\n","\n","class DataSplit(str, enum.Enum):\n","    TRAIN = \"train\"\n","    VALIDATION = \"validation\"\n","    TEST = \"test\"\n","\n","\n","class AudioTransformType(str, enum.Enum):\n","    STFT = \"stft\"\n","    LOG_MEL_STFT = \"log_mel_stft\"\n","\n","\n","class EncoderType(str, enum.Enum):\n","    RNN = \"rnn\"\n","    TRANSFORMER = \"transformer\"\n","\n","\n","class DecoderType(str, enum.Enum):\n","    RNN = \"rnn\"\n","    TRANSFORMER = \"transformer\"\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:31.479932Z","iopub.status.busy":"2023-12-15T17:36:31.479673Z","iopub.status.idle":"2023-12-15T17:36:31.563241Z","shell.execute_reply":"2023-12-15T17:36:31.562577Z","shell.execute_reply.started":"2023-12-15T17:36:31.479907Z"},"id":"1OA5lnc_OWlc","trusted":true},"outputs":[],"source":["# hw2/config.py\n","\n","from ml_collections import config_dict\n","\n","\n","def get_config():\n","    config = config_dict.ConfigDict()\n","    config.seed = 42\n","    config.n_fft = 400\n","    config.n_vocab = 35\n","    config.text_len = 99\n","    config.audio_freq = 80  # number of mel filters\n","    config.audio_time = 2754  # 10 seconds of sound\n","    config.epochs = 15\n","    config.lr = 1e-3\n","    config.unk_token_idx = 3\n","    config.storage_folder = \"./storage\"\n","    config.speech_to_text = dict(\n","        max_text_len=config.get_ref(\"text_len\"),\n","        encoder_kwargs=dict(\n","            n_layers=2,\n","            freq_dim=config.get_ref(\"audio_freq\"),\n","            time_dim=config.get_ref(\"audio_time\") // 2,\n","            hidden_dim=200,\n","            n_heads=2,\n","            feed_fwd_dim=400,\n","        ),\n","        decoder_type=DecoderType.TRANSFORMER,\n","        decoder_kwargs=dict(\n","            freq_dim=config.get_ref(\"n_vocab\"),\n","            time_dim=config.get_ref(\"text_len\"),\n","            hidden_dim=200,\n","            n_heads=2,\n","            feed_fwd_dim=400,\n","        ),\n","    )\n","\n","    config.data = dict(\n","        data_folder=\"./data/\",\n","        data_split=dict(train=(0, 9825), validation=(9825, 10480), test=(10480, 13100)),\n","        dataloader=dict(\n","            train=dict(batch_size=64, shuffle=True, num_workers=2, prefetch_factor=2),\n","            validation=dict(\n","                batch_size=16, shuffle=False, num_workers=2, prefetch_factor=2\n","            ),\n","            test=dict(\n","                batch_size=16, shuffle=False, num_workers=2, prefetch_factor=2\n","            ),\n","        ),\n","        transforms=dict(\n","            audio=dict(\n","                spectrogram=dict(\n","                    n_fft=config.get_ref(\"n_fft\"),\n","                    hop_length=160,\n","                    power=2,\n","                    center=True,\n","                    normalized=False,\n","                    onesided=None,\n","                ),\n","                mel_scale=dict(\n","                    n_mels=config.get_ref(\"audio_freq\"),\n","                    n_stft=config.get_ref(\"n_fft\") // 2 + 1,\n","                    norm=\"slaney\",\n","                    mel_scale=\"slaney\",\n","                ),\n","                pad=dict(\n","                    l=0,\n","                    t=0,\n","                    r=config.get_ref(\"audio_time\"),\n","                    b=0,\n","                ),\n","                freq_masking=dict(freq_mask_param=27),\n","                time_masking=dict(time_mask_param=80),\n","            ),\n","            text=dict(\n","                token_vectorizer=dict(\n","                    max_len=config.get_ref(\"text_len\"),\n","                    start=\"<\",\n","                    stop=\">\",\n","                    empty=\"@\",\n","                    unk=\"#\",\n","                    n_vocab=config.get_ref(\"n_vocab\"),\n","                )\n","            ),\n","        ),\n","    )\n","\n","    return config.lock()\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:31.565324Z","iopub.status.busy":"2023-12-15T17:36:31.565059Z","iopub.status.idle":"2023-12-15T17:36:33.511987Z","shell.execute_reply":"2023-12-15T17:36:33.511025Z","shell.execute_reply.started":"2023-12-15T17:36:31.565300Z"},"id":"pqcDO618mh4I","trusted":true},"outputs":[],"source":["# hw2/data.py\n","\n","import functools\n","import os\n","from typing import Callable, Dict, List, Tuple\n","\n","from ml_collections import config_dict\n","import torch\n","import torchaudio\n","import torchvision\n","\n","\n","class TokenVectorizer(torch.nn.Module):\n","    def __init__(\n","        self,\n","        n_vocab: int,\n","        max_len: int = 50,\n","        start: str = \"<\",\n","        stop: str = \">\",\n","        empty: str = \"@\",\n","        unk: str = \"#\",\n","    ) -> None:\n","        super().__init__()\n","        self._max_len = max_len\n","        self._start = start\n","        self._stop = stop\n","        self._empty = empty\n","        self._unk = unk\n","        self._vocab = [\" \", \",\", \".\", \"?\", \"-\"]\n","        self._vocab += [chr(i + 96) for i in range(1, 27)]\n","\n","        assert self._start not in self._vocab\n","        assert self._stop not in self._vocab\n","        assert self._empty not in self._vocab\n","        assert self._unk not in self._vocab\n","        self._vocab = [self._start, self._stop, self._empty, self._unk] + self._vocab\n","        assert len(self._vocab) == n_vocab\n","        self._unk_idx = 3\n","        self._mapper = {c: i for i, c in enumerate(self._vocab)}\n","        self._inv_mapper = {v: k for k, v in self._mapper.items()}\n","\n","    def forward(self, transcript: str) -> torch.Tensor:\n","        transcript = transcript.lower()[: self._max_len - 2]\n","        transcript = self._start + transcript + self._stop\n","        pad = [self._mapper[self._empty]] * (self._max_len - len(transcript))\n","        return torch.tensor(\n","            [self._mapper.get(c, self._unk_idx) for c in transcript] + pad\n","        )\n","\n","    @property\n","    def invert_mapper(self) -> Dict[int, str]:\n","        return self._inv_mapper\n","\n","    @property\n","    def mapper(self) -> Dict[str, int]:\n","        return self._mapper\n","\n","    @property\n","    def vocab(self) -> List[str]:\n","        return self._vocab\n","\n","\n","class SpeechRecognitionDataset(torch.utils.data.Dataset):\n","    def __init__(\n","        self,\n","        ds: torch.utils.data.Dataset,\n","        get_el: Callable,\n","        audio_transforms: torch.nn.Module,\n","        text_transforms: torch.nn.Module,\n","    ):\n","        self._orig_ds = ds\n","        self._get_el = get_el\n","        self._audio_tf = audio_transforms\n","        self._text_tf = text_transforms\n","\n","    def __getitem__(self, idx):\n","        audio, text = self._get_el(self._orig_ds, idx)\n","        audio = self._audio_tf(audio)\n","        text = self._text_tf(text)\n","        return audio, text\n","\n","    def __len__(self):\n","        return len(self._orig_ds)\n","\n","\n","def _get_ljspeech_el(\n","    ds: torch.utils.data.Dataset, idx: int\n",") -> Tuple[torch.Tensor, torch.Tensor]:\n","    el = ds[idx]\n","    return el[0], el[-1]\n","\n","\n","def _log_mel_stft_transforms(config: config_dict.ConfigDict) -> torch.nn.Module:\n","    def log_mel(x):\n","        log_x = torch.clamp(x, min=1e-10).log10()\n","        log_x = torch.maximum(log_x, log_x.max() - 8.0)\n","        log_x = (log_x + 4.0) / 4.0\n","        return log_x\n","\n","    return torchvision.transforms.Compose(\n","        [\n","            functools.partial(torch.squeeze, dim=0),\n","            torchaudio.transforms.Spectrogram(**config.spectrogram),\n","            torchaudio.transforms.MelScale(**config.mel_scale),\n","            log_mel,\n","            torchvision.transforms.Pad(\n","                (config.pad.l, config.pad.t, config.pad.r, config.pad.b)\n","            ),\n","            lambda x: x[..., :, : config.pad.r],\n","        ]\n","    )\n","\n","\n","def build_dl(\n","    split: DataSplit, config: config_dict.ConfigDict\n",") -> torch.utils.data.DataLoader:\n","    os.makedirs(config.data_folder, exist_ok=True)\n","    orig_ds = torchaudio.datasets.LJSPEECH(config.data_folder, download=True)\n","    get_el = _get_ljspeech_el\n","    audio_tf = _log_mel_stft_transforms(config.transforms.audio)\n","    text_tf = TokenVectorizer(**config.transforms.text.token_vectorizer)\n","\n","    ds = torch.utils.data.Subset(orig_ds, range(*config.data_split.get(split)))\n","    ds = SpeechRecognitionDataset(ds, get_el, audio_tf, text_tf)\n","    dl = torch.utils.data.DataLoader(ds, **config.dataloader.get(split))\n","    return dl\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:33.513731Z","iopub.status.busy":"2023-12-15T17:36:33.513328Z","iopub.status.idle":"2023-12-15T17:36:33.566090Z","shell.execute_reply":"2023-12-15T17:36:33.565173Z","shell.execute_reply.started":"2023-12-15T17:36:33.513705Z"},"id":"2VJPt6aLpoBA","trusted":true},"outputs":[],"source":["# hw2/model.py\n","\n","from typing import Any, Optional, Tuple\n","\n","from ml_collections import config_dict\n","import numpy as np\n","import torch\n","\n","\n","class SpeechToText(torch.nn.Module):\n","    def __init__(\n","        self,\n","        max_text_len: int,\n","        encoder_kwargs: config_dict.ConfigDict,\n","        decoder_type: DecoderType,\n","        decoder_kwargs: config_dict.ConfigDict,\n","    ) -> None:\n","        \"\"\"\n","        text_freq_dim is the vocabulary size.\n","        \"\"\"\n","        super().__init__()\n","        self._max_text_len = max_text_len\n","        self._enc = AudioEncoderTransformer(**encoder_kwargs)\n","        self._dec, self._single_input = self._decoder_factory(\n","            decoder_type, decoder_kwargs\n","        )\n","\n","    def forward(\n","        self, audio_feat: torch.Tensor, text_feat: torch.Tensor\n","    ) -> torch.Tensor:\n","        return self._dec(text_feat, self._enc(audio_feat))\n","\n","    @torch.no_grad()\n","    def generate(self, audio_feat: torch.Tensor) -> torch.Tensor:\n","        enc_feat = self._enc(audio_feat)\n","        text = last_token = torch.zeros(\n","            (enc_feat.shape[0], 1), dtype=torch.long, device=enc_feat.device\n","        )  # vocab index of start token `<` = 0\n","        start_token = True\n","\n","        for _ in range(self._max_text_len - 1):\n","            dec_input = last_token if self._single_input else text\n","            logits = self._dec.generate(dec_input, enc_feat, start_token)\n","            tokens = torch.argmax(logits, dim=-2)\n","            last_token = tokens[:, -1:]\n","            text = torch.concat([text, last_token], axis=-1)\n","            start_token = False\n","\n","        return text\n","\n","    def _decoder_factory(\n","        self, decoder_type: DecoderType, kwargs: config_dict.ConfigDict\n","    ) -> torch.nn.Module:\n","        if decoder_type == DecoderType.RNN:\n","            return TextDecoderRecurrent(**kwargs), True\n","        elif decoder_type == DecoderType.TRANSFORMER:\n","            return TextDecoderTransformer(**kwargs), False\n","        else:\n","            raise ValueError(f\"Decoder type `{decoder_type}` is not valid.\")\n","\n","\n","class AudioEncoderTransformer(torch.nn.Module):\n","    def __init__(\n","        self,\n","        n_layers: int = 2,\n","        freq_dim: int = 129,\n","        time_dim: int = 2754,\n","        hidden_dim: int = 64,\n","        n_heads: int = 2,\n","        feed_fwd_dim: int = 128,\n","        **kwargs,\n","    ) -> None:\n","        super().__init__()\n","        del kwargs\n","        self._embed = SpeechEmbedding(freq_dim, hidden_dim)  # audio embed\n","        self.register_buffer(\"_pos_embed\", self._pos_encoding(time_dim, hidden_dim))\n","        self._att_blocks = torch.nn.ModuleList(\n","            [\n","                ResidualAttentionBlock(hidden_dim, n_heads, feed_fwd_dim)\n","                for _ in range(n_layers)\n","            ]\n","        )\n","        self._out_norm = torch.nn.LayerNorm(hidden_dim)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        out = x  # (B, F, T)\n","        out = self._embed(out)\n","        out = out + self._pos_embed\n","\n","        for block in self._att_blocks:\n","            out = block(out)\n","\n","        out = self._out_norm(out)\n","        return out  # (B, T, E)\n","\n","    def _pos_encoding(\n","        self, length: int, channels: int, max_timescale: int = 3000\n","    ) -> torch.Tensor:\n","        \"\"\"Returns sinusoids for positional embedding\"\"\"\n","        assert channels % 2 == 0\n","        log_timescale_increment = np.log(max_timescale) / (channels // 2 - 1)\n","        inv_timescales = torch.exp(\n","            -log_timescale_increment * torch.arange(channels // 2)\n","        )\n","        scaled_time = (\n","            torch.arange(length)[:, np.newaxis] * inv_timescales[np.newaxis, :]\n","        )\n","        return torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=1)\n","\n","\n","class TextDecoderTransformer(torch.nn.Module):\n","    def __init__(\n","        self,\n","        freq_dim: int = 35,\n","        time_dim: int = 50,\n","        hidden_dim: int = 64,\n","        n_heads: int = 2,\n","        feed_fwd_dim: int = 128,\n","        **kwargs,\n","    ) -> None:\n","        super().__init__()\n","        del kwargs\n","        self._embed = torch.nn.Embedding(freq_dim, hidden_dim)\n","        self._pos_embed = torch.nn.Parameter(torch.rand(time_dim - 1, hidden_dim))\n","        self._att = ResidualAttentionLayer(hidden_dim, n_heads, feed_fwd_dim)\n","        self._cross_att = ResidualAttentionBlock(hidden_dim, n_heads, feed_fwd_dim)\n","        self._out_norm = torch.nn.LayerNorm(hidden_dim)\n","        self._classifier = torch.nn.Linear(hidden_dim, freq_dim)\n","        mask = torch.empty(time_dim, time_dim).fill_(-np.inf).triu_(1)\n","        self.register_buffer(\"_mask\", mask, persistent=False)\n","\n","    def forward(self, x: torch.Tensor, latent: torch.Tensor) -> torch.Tensor:\n","        # in: x=(B, T_d), T_d: text length (max: 50 tokens)\n","        # in: latent=(B, T_e, H_e), see AudioEncoderTransformer\n","        # out: (B, F_d, T_d), F_d: text freq = num of vocab tokens\n","        # NOTE: when adding `self._pos_embed` don't forget to index its first dimension to have the same size as the input's text length `T_d`.\n","        raise NotImplementedError\n","\n","    def generate(\n","        self, x: torch.Tensor, latent: torch.Tensor, start_token: bool = False\n","    ) -> torch.Tensor:\n","        return self.forward(x, latent)\n","\n","\n","class TextDecoderRecurrent(torch.nn.Module):\n","    def __init__(\n","        self,\n","        n_layers: int = 2,\n","        freq_dim: int = 35,\n","        hidden_dim: int = 64,\n","        n_heads: int = 2,\n","        feed_fwd_dim: int = 128,\n","        **kwargs,\n","    ) -> None:\n","        super().__init__()\n","        del kwargs\n","        self._embed = torch.nn.Embedding(freq_dim, hidden_dim)\n","        self._rnn_norm = torch.nn.LayerNorm(hidden_dim)\n","        self._rnn = torch.nn.LSTM(\n","            hidden_dim, hidden_dim, num_layers=n_layers, batch_first=True\n","        )\n","        self._cross_att = ResidualAttentionBlock(hidden_dim, n_heads, feed_fwd_dim)\n","        self._out_norm = torch.nn.LayerNorm(hidden_dim)\n","        self._classifier = torch.nn.Linear(hidden_dim, freq_dim)\n","        self._state = None\n","        \n","    def forward(\n","        self, x: torch.Tensor, latent: torch.Tensor, state: Any = None\n","    ) -> torch.Tensor:\n","        return self._forward(x, latent, state)[0]\n","\n","    def generate(\n","        self, x: torch.Tensor, latent: torch.Tensor, start_token: bool = False\n","    ) -> torch.Tensor:\n","        if start_token:\n","            self._state = None\n","\n","        out, self._state = self._forward(x, latent, self._state)\n","        return out\n","\n","    def _forward(\n","        self, x: torch.Tensor, latent: torch.Tensor, state: Any\n","    ) -> Tuple[torch.Tensor, Any]:\n","        \n","        # 1. Embedding layer\n","        embedded = self._embed(x)  # shape: (B, T_d, H_d)\n","\n","        # 2. Normalization layer followed by an LSTM\n","        embedded = self._rnn_norm(embedded)\n","        rnn_out, new_state = self._rnn(embedded, state)\n","\n","        # 3. Residual cross-attention block\n","        cross_att_out = self._cross_att(rnn_out, latent)  # Assuming the LSTM output is the query\n","\n","        # 4. Normalize the residual block output\n","        cross_att_out = self._out_norm(cross_att_out)\n","\n","        # 5. Single linear layer (classifier)\n","        logits = self._classifier(cross_att_out)\n","\n","        return logits, new_state\n","        # in: x=(B, T_d), T_d: text length (50 tokens w/ padding if needed)\n","        # in: latent=(B, T_e, H_e), see AudioEncoderTransformer\n","        # in: state=((N, B, H_d), (N, B, H_d)), N: number of RNN layers (see __init__), H_d: hidden dim of RNN\n","        # out is a tuple\n","        # out[0]: (B, F_d, T_d), F_d: text freq = num of vocab tokens\n","        # out[1]: rnn's final state\n","        #raise NotImplementedError\n","\n","\n","class ResidualAttentionBlock(torch.nn.Module):\n","    def __init__(\n","        self,\n","        hidden_dim: int = 64,\n","        n_heads: int = 2,\n","        feed_fwd_dim: int = 128\n","    ) -> None:\n","        super().__init__()\n","        self._att_norm = torch.nn.LayerNorm(hidden_dim)\n","        self._att = MultiHeadAttention(hidden_dim, n_heads)\n","        self._mlp_norm = torch.nn.LayerNorm(hidden_dim)\n","        self._mlp = torch.nn.Sequential(\n","            torch.nn.Linear(hidden_dim, feed_fwd_dim),\n","            torch.nn.GELU(),\n","            torch.nn.Linear(feed_fwd_dim, hidden_dim),\n","        )\n","\n","    def forward(\n","        self, x: torch.Tensor, cross_x: Optional[torch.Tensor] = None\n","    ) -> torch.Tensor:\n","        out = x\n","        out = out + self._att(self._att_norm(out), cross_x)\n","        out = out + self._mlp(self._mlp_norm(out))\n","        return out\n","    \n","\n","class ResidualAttentionLayer(torch.nn.Module):\n","    def __init__(\n","        self, hidden_dim: int = 64, n_heads: int = 2, feed_fwd_dim: int = 128\n","    ) -> None:\n","        super().__init__()\n","        self._att_norm = torch.nn.LayerNorm(hidden_dim)\n","        self._att = MultiHeadAttention(hidden_dim, n_heads)\n","\n","    def forward(\n","        self, x: torch.Tensor, mask: Optional[torch.Tensor] = None,\n","    ) -> torch.Tensor:\n","        out = x\n","        out = out + self._att(self._att_norm(out), mask=mask)\n","        return out\n","\n","\n","class MultiHeadAttention(torch.nn.Module):\n","    \"\"\"Simple multi head attn implementation, torch's version has unnecessary overhead.\"\"\"\n","\n","    def __init__(self, hidden_dim: int, n_heads: int):\n","        super().__init__()\n","        self._n_heads = n_heads\n","        self._query = torch.nn.Linear(hidden_dim, hidden_dim)\n","        self._key = torch.nn.Linear(hidden_dim, hidden_dim, bias=False)\n","        self._value = torch.nn.Linear(hidden_dim, hidden_dim)\n","        self._out = torch.nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(\n","        self,\n","        x: torch.Tensor,\n","        xa: Optional[torch.Tensor] = None,\n","        mask: Optional[torch.Tensor] = None,\n","    ):\n","        q = self._query(x)\n","        k = self._key(x if xa is None else xa)\n","        v = self._value(x if xa is None else xa)\n","        wv = self._qkv_attention(q, k, v, mask)\n","        return self._out(wv)\n","\n","    def _qkv_attention(\n","        self,\n","        q: torch.Tensor,\n","        k: torch.Tensor,\n","        v: torch.Tensor,\n","        mask: Optional[torch.Tensor] = None,\n","    ):\n","        _, n_seq, hidden_dim = q.shape\n","        scale = (hidden_dim // self._n_heads) ** -0.25\n","        q = q.view(*q.shape[:2], self._n_heads, -1).permute(0, 2, 1, 3) * scale\n","        k = k.view(*k.shape[:2], self._n_heads, -1).permute(0, 2, 3, 1) * scale\n","        v = v.view(*v.shape[:2], self._n_heads, -1).permute(0, 2, 1, 3)\n","\n","        qk = q @ k\n","\n","        if mask is not None:\n","            qk = qk + mask[:n_seq, :n_seq]\n","\n","        qk = qk.float()\n","        w = torch.nn.functional.softmax(qk, dim=-1).to(q.dtype)\n","        return (w @ v).permute(0, 2, 1, 3).flatten(start_dim=2)\n","\n","\n","class SpeechEmbedding(torch.nn.Module):\n","    def __init__(\n","        self, in_dim: int = 129, hidden_dim: int = 64, kernel: int = 3\n","    ) -> None:\n","        super().__init__()\n","        self._embed = torch.nn.Sequential(\n","            torch.nn.Conv1d(in_dim, hidden_dim, kernel_size=kernel, padding=1),\n","            torch.nn.GELU(),\n","            torch.nn.Conv1d(\n","                hidden_dim, hidden_dim, kernel_size=kernel, stride=2, padding=1\n","            ),\n","            torch.nn.GELU(),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        x : torch.Tensor, shape = (bs, freq, time), freq can be n_fft (when converting\n","            audio into spectrogram) or n_mels (when converting audio into mel\n","            spectrogram).\n","        \"\"\"\n","        out = x\n","        out = self._embed(out)\n","        out = out.permute(0, 2, 1)\n","        return out\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:33.568087Z","iopub.status.busy":"2023-12-15T17:36:33.567715Z","iopub.status.idle":"2023-12-15T17:36:33.614167Z","shell.execute_reply":"2023-12-15T17:36:33.613361Z","shell.execute_reply.started":"2023-12-15T17:36:33.568055Z"},"id":"VL6vg3hwpqls","trusted":true},"outputs":[],"source":["# hw2/trainer.py\n","\n","import os\n","import pathlib as pl\n","from typing import Callable, Dict, List, Tuple, Union\n","\n","from ml_collections import config_dict\n","import numpy as np\n","import textdistance as td\n","import torch\n","\n","\n","class Trainer:\n","    def __init__(self, config: config_dict.ConfigDict, device: str = \"cpu\"):\n","        self._device = torch.device(device)\n","        self._config = config\n","        self._save_step = np.linspace(0, config.epochs, num=10, dtype=np.int32)\n","        self._model = SpeechToText(**config.speech_to_text)\n","        self._model.to(self._device)\n","        self._opt = torch.optim.AdamW(self._model.parameters(), lr=config.lr)\n","        warm_up_sch = torch.optim.lr_scheduler.LinearLR(\n","            self._opt, 1e-2, 1, int(0.15 * config.epochs)\n","        )\n","        decay_sch = torch.optim.lr_scheduler.LinearLR(\n","            self._opt, 1, 1e-2, int(0.85 * config.epochs)\n","        )\n","        self._opt_sch = torch.optim.lr_scheduler.SequentialLR(\n","            self._opt, [warm_up_sch, decay_sch], [int(0.15 * config.epochs)]\n","        )\n","        self._run_loss = 0.0\n","        self._log_train_step_int = 30\n","        self._prev_log_step = 0\n","\n","        self._text_vec = TokenVectorizer(\n","            **config.data.transforms.text.token_vectorizer\n","        )\n","        self._stop_token_idx = self._text_vec.mapper[self._text_vec._stop]\n","        self._empty_token = self._text_vec._empty\n","        self._str_algos = {\n","            \"jaccard_similarity\": td.jaccard.normalized_similarity,\n","            \"cosine_similarity\": td.cosine.normalized_similarity,\n","            \"damerau-levenshtein_similarity\": td.damerau_levenshtein.normalized_similarity,\n","        }\n","        self._metrics = []\n","        self._storage_path = pl.Path(self._config.storage_folder)\n","        self._storage_path /= str(self._config.seed)\n","        os.makedirs(self._storage_path, exist_ok=True)\n","\n","    def train(self) -> None:\n","        train_dl = build_dl(DataSplit.TRAIN, self._config.data)\n","        val_dl = build_dl(DataSplit.VALIDATION, self._config.data)\n","\n","        for epoch in range(self._config.epochs):\n","            metrics = {}\n","            self._prev_log_step = 0\n","            print(f\"[{epoch + 1}]\\ntrain:\")\n","\n","            for step, data in enumerate(train_dl):\n","                audio, text = data[0].to(self._device), data[1].to(self._device)\n","                train_metrics = self._train_step(audio, text)\n","                metrics = self._upt_metrics(metrics, train_metrics, \"train\")\n","                self._log_train(epoch, step, metrics[\"train\"])\n","\n","            print(\"\\nvalidation:\")\n","\n","            for step, data in enumerate(val_dl):\n","                audio, text = data[0].to(self._device), data[1].to(self._device)\n","                val_metrics, log = self._eval_step(audio, text, step + 1 == len(val_dl))\n","                metrics = self._upt_metrics(metrics, val_metrics, \"val\")\n","\n","            self._log_val(step, metrics[\"val\"], log)\n","            self._opt_sch.step()\n","            self._metrics.append(metrics)\n","\n","            if epoch in self._save_step:\n","                model_file = self._storage_path\n","                model_file /= f\"audio_to_text__{epoch}.pt\"\n","                torch.save(self._model.state_dict(), (model_file))\n","\n","        metrics_file = self._storage_path\n","        metrics_file /= f\"train_metrics__{self._config.epochs}.pkl\"\n","        save_obj(self._metrics, metrics_file)\n","\n","    def test(self) -> None:\n","        test_dl = build_dl(DataSplit.TEST, self._config.data)\n","        metrics = {}\n","        log = []\n","\n","        for data in test_dl:\n","            audio, text = data[0].to(self._device), data[1].to(self._device)\n","            batch_metrics, batch_log = self._eval_step(audio, text, True)\n","            metrics = self._upt_metrics(metrics, batch_metrics, \"test\")\n","            log += batch_log\n","\n","        metrics_file = self._storage_path\n","        metrics_file /= f\"test_metrics__{self._config.epochs}.pkl\"\n","        save_obj(metrics, metrics_file)\n","\n","        log_file = self._storage_path\n","        log_file /= f\"test_log__{self._config.epochs}.txt\"\n","        save_txt(\"\".join(log), log_file)\n","\n","    def _train_step(self, audio: torch.Tensor, text: torch.Tensor) -> float:\n","        self._opt.zero_grad()\n","        loss = self._fwd_step(audio, text)\n","        loss.backward()\n","        self._opt.step()\n","        return {\"loss\": loss.item()}\n","\n","    @torch.no_grad()\n","    def _eval_step(\n","        self, audio: torch.Tensor, text: torch.Tensor, log_text: bool = False\n","    ) -> Tuple[Dict[str, float], str]:\n","        loss = self._fwd_step(audio, text).item()\n","        gen_text = self._model.generate(audio)\n","        text, gen_text = text.cpu().numpy(), gen_text.cpu().numpy()\n","        metrics = self._str_sim_algos(self._str_algos, text, gen_text)\n","        metrics[\"loss\"] = loss\n","        metrics[\"n\"] = text.shape[0]\n","\n","        if not log_text:\n","            return metrics, \"\"\n","\n","        return metrics, self._cmp_target_w_gen(text, gen_text)\n","\n","    def _fwd_step(self, audio: torch.Tensor, text: torch.Tensor) -> torch.Tensor:\n","        target = text[:, 1:]\n","        logits = self._model(audio, text[:, :-1])\n","        loss = torch.nn.functional.cross_entropy(logits, target, label_smoothing=0.1)\n","        return loss\n","\n","    def _create_dataset(self, split: DataSplit):\n","        return\n","\n","    def _log_train(self, epoch: int, step: int, metrics: Dict[str, float]) -> None:\n","        if step % self._log_train_step_int != self._log_train_step_int - 1:\n","            return\n","\n","        print(f\"[{epoch + 1}, {step + 1:4d}]\", end=\" \")\n","        n = step - self._prev_log_step + 1\n","\n","        for m, v in metrics.items():\n","            print(f\"{m}: {sum(v[self._prev_log_step:]) / n:.3f}\")\n","            self._prev_log_step = step + 1\n","\n","    def _log_val(\n","        self, step: int, metrics: Dict[str, Union[float, str]], log: str\n","    ) -> None:\n","        n = sum(metrics[\"n\"])\n","\n","        for k, v in metrics.items():\n","            if k == \"n\":\n","                continue\n","\n","            print(k)\n","            v = sum(v)\n","            v = v / n if k != \"loss\" else v / len(metrics[\"n\"])  # loss is already avg.\n","            print(f\"{v:.3f}\", end=\"\\n\\n\")\n","\n","        print(\"compare-text-gen:\")\n","        print(log, end=\"\\n\\n\")\n","\n","    def _upt_metrics(\n","        self, base: Dict[str, float], upt: Dict[str, float], phase: str\n","    ) -> Dict[str, float]:\n","        base_phase = base.get(phase, {})\n","\n","        for k in upt:\n","            if k not in base_phase:\n","                base_phase[k] = []\n","\n","            base_phase[k].append(upt[k])\n","\n","        base[phase] = base_phase\n","        return base\n","\n","    def _str_sim_algos(\n","        self, str_algos: Dict[str, Callable], target: np.ndarray, gen: np.ndarray\n","    ) -> Dict[str, float]:\n","        metrics = {k: 0 for k in str_algos}\n","\n","        for t, g in zip(target, gen):\n","            t, g = self._preprocess_text(t, g)\n","\n","            for k, algo_fn in str_algos.items():\n","                metrics[k] += algo_fn(t, g)\n","\n","        return metrics\n","\n","    def _cmp_target_w_gen(self, target: np.ndarray, gen: np.ndarray) -> str:\n","        cmp = []\n","\n","        for t, g in zip(target, gen):\n","            t = \"\".join([self._text_vec.invert_mapper[c] for c in t])\n","            t = t.replace(\"@\", \"\")\n","            last_idx = np.where(g == 1)[0]\n","            last_idx = last_idx[0] + 1 if last_idx.size > 0 else g.shape[0]\n","            g = g[:last_idx]\n","            g = \"\".join([self._text_vec.invert_mapper[c] for c in g])\n","            cmp += [\"target: \", t, \"\\n\", \"pred:   \", g, \"\\n\\n\"]\n","\n","        return \"\".join(cmp)\n","\n","    def _preprocess_text(\n","        self, target: np.ndarray, gen: np.ndarray\n","    ) -> Tuple[List[str], List[str]]:\n","        last_idx = np.where((target == self._stop_token_idx))[0][0]\n","        target = target[: last_idx + 1]\n","        last_idx = np.where(gen == 1)[0]\n","        last_idx = last_idx[0] if last_idx.size > 0 else len(gen) - 1\n","        gen[last_idx] = 1\n","        gen = gen[: last_idx + 1]\n","        return target.tolist(), gen.tolist()\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:33.615843Z","iopub.status.busy":"2023-12-15T17:36:33.615467Z","iopub.status.idle":"2023-12-15T17:36:33.624513Z","shell.execute_reply":"2023-12-15T17:36:33.623592Z","shell.execute_reply.started":"2023-12-15T17:36:33.615809Z"},"trusted":true},"outputs":[],"source":["# main.py\n","\n","import random\n","\n","\n","def plotting(config):\n","    epochs, seed = config.epochs, config.seed\n","    metrics_path = pl.Path(config.storage_folder) / str(seed)\n","    plot_path = metrics_path / \"plots\"\n","    os.makedirs(plot_path, exist_ok=True)\n","\n","    labels = {\"train\": \"train\", \"val\": \"validation\"}\n","    train_metrics_path = metrics_path / f\"train_metrics__{epochs}.pkl\"\n","    train_metrics = load_metrics(train_metrics_path)\n","    plot_metrics(train_metrics, plot_path, \"train\")\n","    plot_metrics(train_metrics, plot_path, \"val\")\n","    cmp_phase_metrics(train_metrics, \"loss\", [\"train\", \"val\"], plot_path, labels)\n","\n","    test_metrics_path = metrics_path / f\"test_metrics__{epochs}.pkl\"\n","    test_metrics = load_metrics(test_metrics_path)[\"test\"]\n","    mean_test_metrics = {}\n","\n","    for k, v in test_metrics.items():\n","        if k == \"n\":\n","            continue\n","\n","        if k == \"loss\":\n","            mean_test_metrics[k] = sum(v) / len(test_metrics[\"n\"])\n","        else:\n","            mean_test_metrics[k] = sum(v) / sum(test_metrics[\"n\"])\n","\n","    print(\"test:\")\n","    print(mean_test_metrics)"]},{"cell_type":"markdown","metadata":{},"source":["## (a)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T17:36:44.651096Z","iopub.status.busy":"2023-12-15T17:36:44.650733Z","iopub.status.idle":"2023-12-15T17:59:45.904767Z","shell.execute_reply":"2023-12-15T17:59:45.903736Z","shell.execute_reply.started":"2023-12-15T17:36:44.651067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu\n"]},{"ename":"URLError","evalue":"<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)>","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1075\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Training & testing\u001b[39;00m\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(config, DEVICE)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Plotting - check './storage/attention-rnn/{seed}/plots\u001b[39;00m\n","Cell \u001b[0;32mIn[24], line 50\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     train_dl \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataSplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     val_dl \u001b[38;5;241m=\u001b[39m build_dl(DataSplit\u001b[38;5;241m.\u001b[39mVALIDATION, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mepochs):\n","Cell \u001b[0;32mIn[22], line 118\u001b[0m, in \u001b[0;36mbuild_dl\u001b[0;34m(split, config)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_dl\u001b[39m(\n\u001b[1;32m    115\u001b[0m     split: DataSplit, config: config_dict\u001b[38;5;241m.\u001b[39mConfigDict\n\u001b[1;32m    116\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader:\n\u001b[1;32m    117\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(config\u001b[38;5;241m.\u001b[39mdata_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 118\u001b[0m     orig_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLJSPEECH\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     get_el \u001b[38;5;241m=\u001b[39m _get_ljspeech_el\n\u001b[1;32m    120\u001b[0m     audio_tf \u001b[38;5;241m=\u001b[39m _log_mel_stft_transforms(config\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39maudio)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchaudio/datasets/ljspeech.py:43\u001b[0m, in \u001b[0;36mLJSPEECH.__init__\u001b[0;34m(self, root, url, folder_in_archive, download)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     download: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_filesystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_in_archive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchaudio/datasets/ljspeech.py:61\u001b[0m, in \u001b[0;36mLJSPEECH._parse_filesystem\u001b[0;34m(self, root, url, folder_in_archive, download)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(archive):\n\u001b[1;32m     60\u001b[0m             checksum \u001b[38;5;241m=\u001b[39m _RELEASE_CONFIGS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelease1\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchecksum\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 61\u001b[0m             \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         _extract_tar(archive)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/hub.py:620\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    618\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.hub\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m--> 620\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m meta \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(meta, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetheaders\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n","\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)>"]}],"source":["if __name__ == \"__main__\":\n","    # not using absl (no need for command line), get config manually\n","    config = get_config()\n","    config.unlock()  # update hyperparams before `config.lock()`\n","    config.storage_folder = \"./storage/attention-rnn\"\n","    config.speech_to_text.decoder_type = DecoderType.RNN\n","    config.speech_to_text.decoder_kwargs = dict(\n","        n_layers=1,\n","        freq_dim=config.get_ref(\"n_vocab\"),\n","        time_dim=config.get_ref(\"text_len\"),\n","        hidden_dim=200,\n","        n_heads=2,\n","        feed_fwd_dim=400\n","    )\n","    config.lock()\n","\n","    # Manual seed\n","    torch.manual_seed(config.seed)\n","    np.random.seed(config.seed)\n","    random.seed(config.seed)\n","\n","    # Device to use\n","    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f\"Using {DEVICE}\")\n","\n","    # Training & testing\n","    trainer = Trainer(config, DEVICE)\n","    trainer.train()\n","    trainer.test()\n","\n","    # Plotting - check './storage/attention-rnn/{seed}/plots\n","    plotting(config)"]},{"cell_type":"markdown","metadata":{},"source":["## (b)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T18:01:22.385134Z","iopub.status.busy":"2023-12-15T18:01:22.384568Z","iopub.status.idle":"2023-12-15T18:16:50.079656Z","shell.execute_reply":"2023-12-15T18:16:50.078607Z","shell.execute_reply.started":"2023-12-15T18:01:22.385099Z"},"id":"nwz_4GeR1GLN","outputId":"e68a6bac-3962-46f2-fb51-093692c8377d","trusted":true},"outputs":[],"source":["if __name__ == \"__main__\":\n","    # not using absl (no need for command line), get config manually\n","    config = get_config()\n","    config.unlock() # update hyperparams before `config.lock()`\n","    config.storage_folder = \"./storage/attention-attention\"\n","    config.speech_to_text.decoder_type = DecoderType.TRANSFORMER\n","    config.speech_to_text.decoder_kwargs = dict(\n","        freq_dim=config.get_ref(\"n_vocab\"),\n","        time_dim=config.get_ref(\"text_len\"),\n","        hidden_dim=200,\n","        n_heads=2,\n","        feed_fwd_dim=400\n","    )\n","    config.lock()\n","\n","    # Manual seed\n","    torch.manual_seed(config.seed)\n","    np.random.seed(config.seed)\n","    random.seed(config.seed)\n","\n","    # Device to use\n","    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f\"Using {DEVICE}\")\n","\n","    # Training & testing\n","    trainer = Trainer(config, DEVICE)\n","    trainer.train()\n","    trainer.test()\n","\n","    # Plotting - check './storage/attention-attention/{seed}/plots\n","    plotting(config)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
